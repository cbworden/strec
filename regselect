#!/usr/bin/env python

#stdlib imports
import argparse
import sys
import re

#third party imports
import pandas as pd
from libcomcat.search import get_event_by_id

#local imports
from strec.gmreg import Regionalizer


def read_input_file(input_file):
    df = None
    try:
        df = pd.read_csv(input_file)
    except:
        try:
            df = pd.read_excel(input_file)
        except:
            pass
    row_ok,msg = check_row(df.columns)
    if not row_ok:
        df = None
    return (df,msg)
        
def check_row(row):
    #row is a pandas series object
    if not row.str.contains('^lat',case=False).any():
        return False,'Missing "lat" column in input.'
    if not row.str.contains('^lon',case=False).any():
        return False,'Missing "lon" column in input.'
    if not row.str.contains('^depth',case=False).any():
        return False,'Missing "depth" column in input.'
    return (True,'')

def get_input_columns(row):
    #row is a pandas series object
    lat = row[row.index.str.contains('^lat',case=False)][0]
    lon = row[row.index.str.contains('^lon',case=False)][0]
    depth = row[row.index.str.contains('^depth',case=False)][0]

    return (lat,lon,depth)

def render_row(row,format,lat,lon,depth):
    if format == 'pretty':
        print('For event located at %.4f,%.4f,%.1f:' % (lat,lon,depth))
        for idx,value in row.iteritems():
            if re.match('^lat|^lon|^depth',idx,re.IGNORECASE):
                continue
            print('\t%s : %s' % (idx,str(value)))
        print()
    elif format == 'json':
        print(row.to_json())
    elif format == 'csv':
        values = [str(v) for v in row.values]
        print(','.join(values))

def main(args,pparser):
    #check input arguments
    haseq = args.eqinfo is not None
    hasinput = args.input_file is not None
    hasid = args.event_id is not None
    if (haseq+hasinput+hasid) >= 2:
        print('Must choose no more than one of -e or -i or -d options.')
        sys.exit(1)

    if args.event_id:
        try:
            detail = get_event_by_id(args.event_id)
            lat,lon,depth = (detail.latitude,detail.longitude,detail.depth)
        except Exception as e:
            msg = 'Could not get event information on event ID %s due to error "%s".'
            tpl = (args.event_id,str(e))
            print(msg % tpl)
            sys.exit(1)
        d = {'lat':[lat],'lon':[lon],'depth':[depth]}
        df = pd.DataFrame(d)
        
    if not args.output_file and args.output_format == 'excel':
        print('You cannot specify an output format of excel without also providing an output file name.')
        sys.exit(1)

    if args.input_file:
        df,msg = read_input_file(args.input_file)
        if df is None:
            print('Input file %s does not appear to be either a CSV or Excel file.  Returning.' % args.input_file)
            sys.exit(1)

    elif args.eqinfo:
        lat,lon,depth = args.eqinfo
        d = {'lat':[lat],'lon':[lon],'depth':[depth]}
        df = pd.DataFrame(d)
        
    regionalizer = Regionalizer.load()
    results = []
    for idx,row in df.iterrows():
        lat,lon,depth = get_input_columns(row)
        result = regionalizer.getRegions(lat,lon,depth)
        dtypes = {'Oceanic':bool}
        row = row.append(result)
            
        # #because I cannot figure out how to change the data type of an index in a series,
        # #I'll convert the row to a one-row dataframe, change the datatypes of the columns,
        # #then get back the row.  Stupid.
        # df = pd.DataFrame(columns=row.index)
        # df = df.append(row)
        # df = df.astype(dtypes)
        # row = df.iloc[0]
        if args.output_file:
            results.append(row)
        else:
            render_row(row,args.output_format,lat,lon,depth)
    if args.output_file:
        df = pd.DataFrame(results)
        if args.output_format == 'csv':
            df.to_csv(args.output_file)
        else:
            df.to_excel(args.output_file)

if __name__ == '__main__':
    usage = """Determine various seismo-tectonic parameters for given input coordinates.
    GMREG - Ground Motion Regionalization Tool

The output will consist of the following "columns" of data:

Tectonic Region
  - Active : is this point in a tectonically active region? (True/False)
  - Stable : is this point in a tectonically stable region? (True/False)
  - Subduction : is this point in a subduction zone? (True/False)
  - Active Volcanic : is this point in an active volcanic zone? (True/False)

Oceanic - is this point in an oceanic region? (True/False)

Each tectonic region will have a subordinate "Tectonic Domain", consisting of one of the following:

 - ACR oceanic boundary (above slab)
 - ACR deep (above slab)
 - ACR shallow (above slab)
 - SOR (above slab)
 - SOR (generic)
 - SZ (inland/back-arc)
 - SZ (on-shore)
 - SZ (outer-trench)
 - SZ (generic)
 - ACR (hot spot)
 - ACR (oceanic boundary)
 - ACR (deep)
 - ACR (shallow)
 - SCR (above slab)
 - SCR (generic)

Usage:

%(prog)s -e 3.295 95.982 30.0
%(prog)s -d official20041226005853450_30


"""
    input_file_help = '''Input files can be CSV or Excel format (%(prog)s  will attempt to determine
format automatically) and MUST include the following columns (case doesn't matter):

Lat Numeric latitude of input earthquake.
Lon Numeric longitude of input earthquake.

Any other columns present in the input will be copied to the output.
'''

    output_format_help = '''The output format must be one of the following:
 
pretty - A human readable pretty-printed representation of the output.
csv - A CSV output, one earthquake per line.
excel - Microsoft Excel format, one earthquake per line.
json - A JSON representation of the output

'''
     
    parser = argparse.ArgumentParser(description=usage,formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument("-e","--eqinfo",nargs=3,metavar=('LAT', 'LON', 'DEPTH'),type=float,
                        help='lat,lon, depth of earthquake')
    parser.add_argument("-i", "--input-file",dest="input_file",
                        metavar='INPUTFILE',
                        help=input_file_help)
    parser.add_argument("-f", "--output-format",dest="output_format",
                      metavar='OUTPUT FORMAT',choices=('pretty','csv','excel','json'),default='pretty',
                      help=output_format_help)
    parser.add_argument("-o", "--output-file",dest="output_file",help='Output filename')
    parser.add_argument("-d", "--event-id",dest="event_id",help='ComCat Event ID')
    pargs = parser.parse_args()

    main(pargs,parser)

