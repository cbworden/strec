#!/usr/bin/env python

#stdlib imports
import argparse
import sys
import re
import configparser
import os.path

#third party imports
import pandas as pd
import numpy as np

#local imports
from strec.subtype import SubductionSelector
from strec.comcat import ComCat
from strec.cmt import get_tensor_params_from_nodal

def read_input_file(input_file):
    df = None
    try:
        df = pd.read_csv(input_file)
    except:
        try:
            df = pd.read_excel(input_file)
        except:
            pass
    row_ok,msg = check_row(df.columns)
    if not row_ok:
        df = None
    return (df,msg)
        
def check_row(row):
    #row is a pandas series object
    if not row.str.contains('^lat',case=False).any():
        return False,'Missing "lat" column in input.'
    if not row.str.contains('^lon',case=False).any():
        return False,'Missing "lon" column in input.'
    if not row.str.contains('^depth',case=False).any():
        return False,'Missing "depth" column in input.'
    return (True,'')

def check_moment_row(row):
    #row is a pandas series object
    if not row.str.contains('^strike',case=False).any():
        return False
    if not row.str.contains('^dip',case=False).any():
        return False
    if not row.str.contains('^rake',case=False).any():
        return False
    if not row.str.contains('^mag',case=False).any():
        return False
    return True

def get_input_columns(row):
    #row is a pandas series object
    lat = row[row.index.str.contains('^lat',case=False)][0]
    lon = row[row.index.str.contains('^lon',case=False)][0]
    depth = row[row.index.str.contains('^depth',case=False)][0]

    return (lat,lon,depth)

def get_moment_columns(row):
    #row is a pandas series object
    strike = row[row.index.str.contains('^strike',case=False)][0]
    dip = row[row.index.str.contains('^dip',case=False)][0]
    rake = row[row.index.str.contains('^rake',case=False)][0]
    mag = row[row.index.str.contains('^mag',case=False)][0]

    return (strike,dip,rake,mag)

def render_row(row,format,lat,lon,depth):
    if format == 'pretty':
        print('For event located at %.4f,%.4f,%.1f:' % (lat,lon,depth))
        for idx,value in row.iteritems():
            if re.match('^lat|^lon|^depth',idx,re.IGNORECASE):
                continue
            print('\t%s : %s' % (idx,str(value)))
        print()
    elif format == 'json':
        print(row.to_json())
    elif format == 'csv':
        values = [str(v) for v in row.values]
        print(','.join(values))

def main(args,pparser):
    #check input arguments
    #check input arguments
    haseq = args.eqinfo is not None
    hasinput = args.input_file is not None
    hasid = args.event_id is not None
    if (haseq+hasinput+hasid) >= 2:
        print('Must choose no more than one of -e or -i or -d options.')
        sys.exit(1)

    if (hasid or hasinput) and args.moment_info:
        print('Supplying moment tensor information is unnecessary/inapplicablee when also supplying event ID or input file.')
        sys.exit(1)

    if not args.output_file and args.output_format == 'excel':
        print('You cannot specify an output format of excel without also providing an output file name.')
        sys.exit(1)

    tensor_params = None
    selector = SubductionSelector()    
    if args.input_file:
        df,msg = read_input_file(args.input_file)
        if df is None:
            print('Input file %s does not appear to be either a CSV or Excel file.  Returning.' % args.input_file)
            sys.exit(1)
        
    if args.eqinfo:
        lat,lon,depth = args.eqinfo
        d = {'lat':[lat],'lon':[lon],'depth':[depth]}
        df = pd.DataFrame(d)
            
    if args.moment_info:
        strike,dip,rake,mag = args.moment_info
        tensor_params = get_tensor_params_from_nodal(strike,dip,rake,mag)
        
    if args.event_id:
        comcat = ComCat()
        try:
            lat,lon,depth,tensor_params = comcat.getEventProperties(args.event_id)
        except Exception as e:
            msg = 'Could not get event information on event ID %s due to error "%s".'
            tpl = (args.event_id,str(e))
            print(msg % tpl)
            sys.exit(1)
            
        d = {'lat':[lat],'lon':[lon],'depth':[depth]}
        df = pd.DataFrame(d)
    
    results = []
    has_tensor = check_moment_row(df.columns) or tensor_params is not None
    for idx,row in df.iterrows():
        lat,lon,depth = get_input_columns(row)
        if not tensor_params and has_tensor:
            strike,dip,rake,mag = get_moment_columns(row)
            if np.isnan(strike):
                tensor_params = None
            else:
                tensor_params = get_tensor_params_from_nodal(strike,dip,rake,mag)
        result = selector.getSubductionType(lat,lon,depth,tensor_params=tensor_params)
        tensor_params = None
        row = row.append(result)
        if args.output_file:
            results.append(row)
        else:
            render_row(row,args.output_format,lat,lon,depth)
    if args.output_file:
        df = pd.DataFrame(results)
        if args.output_format == 'csv':
            df.to_csv(args.output_file)
        else:
            df.to_excel(args.output_file)

if __name__ == '__main__':
    usage = """Determine various seismo-tectonic parameters for given input coordinates.
    GMREG - Ground Motion Regionalization Tool

The output will consist of the following "columns" of data:

Tectonic Region
  - Active : is this point in a tectonically active region? (True/False)
  - Stable : is this point in a tectonically stable region? (True/False)
  - Subduction : is this point in a subduction zone? (True/False)
  - Active Volcanic : is this point in an active volcanic zone? (True/False)

Oceanic - is this point in an oceanic region? (True/False)
Induced - is this point in an induced seismicity region? (True/False)

Each tectonic region will have a subordinate "Tectonic Domain", consisting of one of the following:

 - ACR oceanic boundary (above slab)
 - ACR deep (above slab)
 - ACR shallow (above slab)
 - SOR (above slab)
 - SOR (generic)
 - SZ (inland/back-arc)
 - SZ (on-shore)
 - SZ (outer-trench)
 - SZ (generic)
 - ACR (hot spot)
 - ACR (oceanic boundary)
 - ACR (deep)
 - ACR (shallow)
 - SCR (above slab)
 - SCR (generic)

There will also be a list of not necessarily mutually exclusive geographic regions, which are provided
mostly to aid in choosing Ground Motion Prediction Equations (GMPEs) or Intensity Prediction Equations 
(IPEs).  These will grow over time as the maintainers find new regions that need to be delineated for this
purpose.


"""
    input_file_help = '''Input files can be CSV or Excel format (%(prog)s  will attempt to determine
format automatically) and MUST include the following columns (case doesn't matter):

Lat Numeric latitude of input earthquake.
Lon Numeric longitude of input earthquake.

Any other columns present in the input will be copied to the output.
'''

    output_format_help = '''The output format must be one of the following:
 
pretty - A human readable pretty-printed representation of the output.
csv - A CSV output, one earthquake per line.
excel - Microsoft Excel format, one earthquake per line.
json - A JSON representation of the output

'''
     
    parser = argparse.ArgumentParser(description=usage,formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument("-e","--eqinfo",nargs=3,metavar=('LAT', 'LON', 'DEPTH'),type=float,
                        help='lat,lon, depth of earthquake')
    parser.add_argument("-i", "--input-file",dest="input_file",
                        metavar='INPUTFILE',
                        help=input_file_help)
    parser.add_argument("-f", "--output-format",dest="output_format",
                      metavar='OUTPUT FORMAT',choices=('pretty','csv','excel','json'),default='pretty',
                      help=output_format_help)
    parser.add_argument("-o", "--output-file",dest="output_file",help='Output filename')
    parser.add_argument("-m","--moment-info",nargs=4,metavar=('STRIKE', 'DIP', 'RAKE','MAG'),type=float,
                        help='strike,dip,rake,magnitude of earthquake')
    parser.add_argument("-d", "--event-id",dest="event_id",help='ComCat Event ID')
    pargs = parser.parse_args()

    main(pargs,parser)

